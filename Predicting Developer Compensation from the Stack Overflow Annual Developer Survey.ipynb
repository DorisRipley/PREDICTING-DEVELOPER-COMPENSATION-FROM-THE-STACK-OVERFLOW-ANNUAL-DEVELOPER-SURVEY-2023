{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "919ca8cf",
   "metadata": {},
   "source": [
    "# Predicting Developer Compensation from the Stack Overflow Annual Developer Survey"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b149b95",
   "metadata": {},
   "source": [
    "### Introduction: Understanding Developer Compensation with Data Science\n",
    "\n",
    "In today's fast-evolving tech landscape, understanding the factors that influence a developer's compensation is crucial for both employers and employees. Compensation isn't just a reflection of one's skills and experience; it's an intricate interplay of various factors ranging from geographical location and educational background to specific tech stacks and organizational roles. The Stack Overflow Annual Developer Survey, one of the most comprehensive datasets about developers globally, offers a unique lens through which we can analyze and predict developer compensation.\n",
    "\n",
    "This project dives deep into the survey's rich dataset, aiming to categorize developers into distinct salary brackets. Through rigorous data preprocessing, exploratory analysis, and advanced machine learning techniques, we unravel the intricacies of developer compensation. Join us as we embark on this analytical journey, navigating the challenges of real-world data and uncovering insights that could reshape our understanding of the tech industry's compensation dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf261a9f",
   "metadata": {},
   "source": [
    "let's start by examining the dataset to determine its features and potential classification strategies. First, we'll take a look at the first few rows and the overall structure of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "43782a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 89184 entries, 0 to 89183\n",
      "Data columns (total 84 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   ResponseId                           89184 non-null  int64  \n",
      " 1   Q120                                 89184 non-null  object \n",
      " 2   MainBranch                           89184 non-null  object \n",
      " 3   Age                                  89184 non-null  object \n",
      " 4   Employment                           87898 non-null  object \n",
      " 5   RemoteWork                           73810 non-null  object \n",
      " 6   CodingActivities                     73764 non-null  object \n",
      " 7   EdLevel                              87973 non-null  object \n",
      " 8   LearnCode                            87663 non-null  object \n",
      " 9   LearnCodeOnline                      70084 non-null  object \n",
      " 10  LearnCodeCoursesCert                 37076 non-null  object \n",
      " 11  YearsCode                            87435 non-null  object \n",
      " 12  YearsCodePro                         66136 non-null  object \n",
      " 13  DevType                              76872 non-null  object \n",
      " 14  OrgSize                              65043 non-null  object \n",
      " 15  PurchaseInfluence                    64964 non-null  object \n",
      " 16  TechList                             60851 non-null  object \n",
      " 17  BuyNewTool                           83009 non-null  object \n",
      " 18  Country                              87973 non-null  object \n",
      " 19  Currency                             65334 non-null  object \n",
      " 20  CompTotal                            48225 non-null  float64\n",
      " 21  LanguageHaveWorkedWith               87140 non-null  object \n",
      " 22  LanguageWantToWorkWith               80709 non-null  object \n",
      " 23  DatabaseHaveWorkedWith               73435 non-null  object \n",
      " 24  DatabaseWantToWorkWith               60911 non-null  object \n",
      " 25  PlatformHaveWorkedWith               63628 non-null  object \n",
      " 26  PlatformWantToWorkWith               51308 non-null  object \n",
      " 27  WebframeHaveWorkedWith               66938 non-null  object \n",
      " 28  WebframeWantToWorkWith               56741 non-null  object \n",
      " 29  MiscTechHaveWorkedWith               57019 non-null  object \n",
      " 30  MiscTechWantToWorkWith               46848 non-null  object \n",
      " 31  ToolsTechHaveWorkedWith              77884 non-null  object \n",
      " 32  ToolsTechWantToWorkWith              68315 non-null  object \n",
      " 33  NEWCollabToolsHaveWorkedWith         85864 non-null  object \n",
      " 34  NEWCollabToolsWantToWorkWith         76649 non-null  object \n",
      " 35  OpSysPersonal use                    86557 non-null  object \n",
      " 36  OpSysProfessional use                78587 non-null  object \n",
      " 37  OfficeStackAsyncHaveWorkedWith       69090 non-null  object \n",
      " 38  OfficeStackAsyncWantToWorkWith       53743 non-null  object \n",
      " 39  OfficeStackSyncHaveWorkedWith        83439 non-null  object \n",
      " 40  OfficeStackSyncWantToWorkWith        69776 non-null  object \n",
      " 41  AISearchHaveWorkedWith               56328 non-null  object \n",
      " 42  AISearchWantToWorkWith               46150 non-null  object \n",
      " 43  AIDevHaveWorkedWith                  25904 non-null  object \n",
      " 44  AIDevWantToWorkWith                  19587 non-null  object \n",
      " 45  NEWSOSites                           87973 non-null  object \n",
      " 46  SOVisitFreq                          87140 non-null  object \n",
      " 47  SOAccount                            87852 non-null  object \n",
      " 48  SOPartFreq                           66061 non-null  object \n",
      " 49  SOComm                               87692 non-null  object \n",
      " 50  SOAI                                 47912 non-null  object \n",
      " 51  AISelect                             87973 non-null  object \n",
      " 52  AISent                               61501 non-null  object \n",
      " 53  AIAcc                                38594 non-null  object \n",
      " 54  AIBen                                61396 non-null  object \n",
      " 55  AIToolInterested in Using            32783 non-null  object \n",
      " 56  AIToolCurrently Using                36137 non-null  object \n",
      " 57  AIToolNot interested in Using        21069 non-null  object \n",
      " 58  AINextVery different                 12661 non-null  object \n",
      " 59  AINextNeither different nor similar  6599 non-null   object \n",
      " 60  AINextSomewhat similar               6238 non-null   object \n",
      " 61  AINextVery similar                   2621 non-null   object \n",
      " 62  AINextSomewhat different             23303 non-null  object \n",
      " 63  TBranch                              65768 non-null  object \n",
      " 64  ICorPM                               43668 non-null  object \n",
      " 65  WorkExp                              43579 non-null  float64\n",
      " 66  Knowledge_1                          42535 non-null  object \n",
      " 67  Knowledge_2                          41670 non-null  object \n",
      " 68  Knowledge_3                          41798 non-null  object \n",
      " 69  Knowledge_4                          41684 non-null  object \n",
      " 70  Knowledge_5                          41527 non-null  object \n",
      " 71  Knowledge_6                          41520 non-null  object \n",
      " 72  Knowledge_7                          41467 non-null  object \n",
      " 73  Knowledge_8                          41404 non-null  object \n",
      " 74  Frequency_1                          41916 non-null  object \n",
      " 75  Frequency_2                          41925 non-null  object \n",
      " 76  Frequency_3                          41054 non-null  object \n",
      " 77  TimeSearching                        42778 non-null  object \n",
      " 78  TimeAnswering                        42629 non-null  object \n",
      " 79  ProfessionalTech                     41783 non-null  object \n",
      " 80  Industry                             36774 non-null  object \n",
      " 81  SurveyLength                         86485 non-null  object \n",
      " 82  SurveyEase                           86554 non-null  object \n",
      " 83  ConvertedCompYearly                  48019 non-null  float64\n",
      "dtypes: float64(3), int64(1), object(80)\n",
      "memory usage: 57.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   ResponseId     Q120                      MainBranch              Age  \\\n",
       " 0           1  I agree                   None of these  18-24 years old   \n",
       " 1           2  I agree  I am a developer by profession  25-34 years old   \n",
       " 2           3  I agree  I am a developer by profession  45-54 years old   \n",
       " 3           4  I agree  I am a developer by profession  25-34 years old   \n",
       " 4           5  I agree  I am a developer by profession  25-34 years old   \n",
       " \n",
       "                                           Employment  \\\n",
       " 0                                                NaN   \n",
       " 1                                Employed, full-time   \n",
       " 2                                Employed, full-time   \n",
       " 3                                Employed, full-time   \n",
       " 4  Employed, full-time;Independent contractor, fr...   \n",
       " \n",
       "                              RemoteWork  \\\n",
       " 0                                   NaN   \n",
       " 1                                Remote   \n",
       " 2  Hybrid (some remote, some in-person)   \n",
       " 3  Hybrid (some remote, some in-person)   \n",
       " 4                                Remote   \n",
       " \n",
       "                                     CodingActivities  \\\n",
       " 0                                                NaN   \n",
       " 1  Hobby;Contribute to open-source projects;Boots...   \n",
       " 2  Hobby;Professional development or self-paced l...   \n",
       " 3                                              Hobby   \n",
       " 4  Hobby;Contribute to open-source projects;Profe...   \n",
       " \n",
       "                                         EdLevel  \\\n",
       " 0                                           NaN   \n",
       " 1  Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
       " 2  Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
       " 3  Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
       " 4  Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
       " \n",
       "                                            LearnCode  \\\n",
       " 0                                                NaN   \n",
       " 1  Books / Physical media;Colleague;Friend or fam...   \n",
       " 2  Books / Physical media;Colleague;On the job tr...   \n",
       " 3  Colleague;Friend or family member;Other online...   \n",
       " 4  Books / Physical media;Online Courses or Certi...   \n",
       " \n",
       "                                      LearnCodeOnline  ...        Frequency_1  \\\n",
       " 0                                                NaN  ...                NaN   \n",
       " 1  Formal documentation provided by the owner of ...  ...   1-2 times a week   \n",
       " 2  Formal documentation provided by the owner of ...  ...  6-10 times a week   \n",
       " 3  Formal documentation provided by the owner of ...  ...   1-2 times a week   \n",
       " 4  Formal documentation provided by the owner of ...  ...   1-2 times a week   \n",
       " \n",
       "          Frequency_2       Frequency_3         TimeSearching  \\\n",
       " 0                NaN               NaN                   NaN   \n",
       " 1   10+ times a week             Never   15-30 minutes a day   \n",
       " 2  6-10 times a week  3-5 times a week   30-60 minutes a day   \n",
       " 3   10+ times a week  1-2 times a week   15-30 minutes a day   \n",
       " 4   1-2 times a week  3-5 times a week  60-120 minutes a day   \n",
       " \n",
       "          TimeAnswering                                   ProfessionalTech  \\\n",
       " 0                  NaN                                                NaN   \n",
       " 1  15-30 minutes a day  DevOps function;Microservices;Automated testin...   \n",
       " 2  30-60 minutes a day  DevOps function;Microservices;Automated testin...   \n",
       " 3  30-60 minutes a day  Automated testing;Continuous integration (CI) ...   \n",
       " 4  30-60 minutes a day  Microservices;Automated testing;Observability ...   \n",
       " \n",
       "                                             Industry           SurveyLength  \\\n",
       " 0                                                NaN                    NaN   \n",
       " 1  Information Services, IT, Software Development...  Appropriate in length   \n",
       " 2  Information Services, IT, Software Development...  Appropriate in length   \n",
       " 3                                                NaN  Appropriate in length   \n",
       " 4                                              Other  Appropriate in length   \n",
       " \n",
       "                    SurveyEase ConvertedCompYearly  \n",
       " 0                         NaN                 NaN  \n",
       " 1                        Easy            285000.0  \n",
       " 2                        Easy            250000.0  \n",
       " 3                        Easy            156000.0  \n",
       " 4  Neither easy nor difficult             23456.0  \n",
       " \n",
       " [5 rows x 84 columns],\n",
       " (89184, 84))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"/Users/doris/Desktop/portafolio/Projects/classification/stack-overflow-developer-survey-2023/survey_results_public.csv\")\n",
    "\n",
    "# Display the first few rows and the overall structure of the dataset\n",
    "data_head = data.head()\n",
    "data_shape = data.shape\n",
    "data_info = data.info()\n",
    "\n",
    "data_head, data_shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584c80ea",
   "metadata": {},
   "source": [
    "The dataset contains 89,184 entries with 84 columns. we first need to define our target variable. Compensation Level: Categorize developers into different salary brackets based on their skills, experience, and other attributes.\n",
    "The next steps involved would be:\n",
    "\n",
    "1. **Define Compensation Brackets:** We'll need to define the salary brackets or categories we want to classify respondents into. For instance: Low, Medium, High, or specific numerical ranges.\n",
    "\n",
    "2. **Data Cleaning:** Address missing values and outliers, especially in the ConvertedCompYearly column which seems to represent the annual compensation.\n",
    "\n",
    "3. **Feature Engineering:** Extract or derive new features that might influence compensation, such as years of experience, technologies known, or education level.\n",
    "\n",
    "4. **Data Transformation:** Convert categorical variables into a format suitable for machine learning and normalize numerical features.\n",
    "\n",
    "5. **Model Selection & Training:** Split the data, select an algorithm, train the model, and validate its performance.\n",
    "\n",
    "6. **Evaluation:** Measure the performance of the model using appropriate metrics.\n",
    "\n",
    "Let's first determine the range of the ConvertedCompYearly values to understand the spread and then replot the histogram with an appropriate bin size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1709781f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 74351432.0, 74963.0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the range of the ConvertedCompYearly values\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Drop NaN values from the ConvertedCompYearly column for visualization\n",
    "compensation_data = data['ConvertedCompYearly'].dropna()\n",
    "\n",
    "\n",
    "compensation_min = compensation_data.min()\n",
    "compensation_max = compensation_data.max()\n",
    "compensation_median = compensation_data.median()\n",
    "\n",
    "compensation_min, compensation_max, compensation_median\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09ab8e4",
   "metadata": {},
   "source": [
    "The range for the ConvertedCompYearly values is quite large, from $\\$1$ to over $\\$74$ million. The median is approximately $\\$75,000$. This wide range suggests the presence of outliers or potentially erroneous entries, which can distort the visualization.\n",
    "\n",
    "To better visualize the distribution without extreme outliers, we can focus on a narrower range around the median. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4abbd62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filtering the data to remove extreme outliers for visualization\n",
    "filtered_compensation_data = compensation_data[(compensation_data >= 1000) & (compensation_data <= 250000)]\n",
    "\n",
    "# Re-plotting the distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(filtered_compensation_data, bins=100, kde=True)\n",
    "plt.title('Distribution of Annual Compensation')\n",
    "plt.xlabel('Annual Compensation')\n",
    "plt.ylabel('Number of Respondents')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07239c78",
   "metadata": {},
   "source": [
    "The distribution of annual compensation is right-skewed, with many respondents in the lower compensation brackets and fewer in the higher ones.\n",
    "To create meaningful classification brackets for \"Compensation Level\", we will use quantiles (percentiles):\n",
    "\n",
    "**Low:** Compensation below the 25th percentile<br />\n",
    "**Medium**: Compensation between the 25th and 75th percentiles<br />\n",
    "**High:** Compensation above the 75th percentile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0d8873",
   "metadata": {},
   "source": [
    "## Step 1: Define Compensation Brackets\n",
    "\n",
    "To classify respondents into compensation levels, we first need to define the boundaries of these levels. Using the data's distribution, we can employ quantiles (percentiles) to segment the data. This method ensures that each category will contain a roughly equal number of respondents, making our classification task more balanced.\n",
    "\n",
    "Let's calculate the 25th and 75th percentiles to determine our \"Low\", \"Medium\", and \"High\" compensation brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "595ff2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44552.0, 117797.0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the 25th and 75th percentiles for the compensation data\n",
    "\n",
    "lower_bound = filtered_compensation_data.quantile(0.25)\n",
    "upper_bound = filtered_compensation_data.quantile(0.75)\n",
    "\n",
    "lower_bound, upper_bound\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d822727",
   "metadata": {},
   "source": [
    "## Step 2: Data Cleaning and Preparation\n",
    "\n",
    "Before we can use the data for modeling, it needs to be cleaned and prepared. This includes handling missing values, encoding categorical variables, and creating our target variable based on the compensation brackets we've defined.\n",
    "\n",
    "Let's create a new column, CompensationLevel, to represent our target variable. We'll then categorize each respondent into one of the three levels based on their ConvertedCompYearly value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a1371240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN       41165\n",
       "Medium    22846\n",
       "High      13066\n",
       "Low       12107\n",
       "Name: CompensationLevel, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the CompensationLevel column based on the defined brackets\n",
    "\n",
    "data['CompensationLevel'] = pd.cut(data['ConvertedCompYearly'], \n",
    "                                   bins=[0, lower_bound, upper_bound, float('inf')], \n",
    "                                   labels=['Low', 'Medium', 'High'], \n",
    "                                   right=False)\n",
    "\n",
    "# Check the distribution of the new CompensationLevel column\n",
    "compensation_level_distribution = data['CompensationLevel'].value_counts(dropna=False)\n",
    "compensation_level_distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf415a90",
   "metadata": {},
   "source": [
    "The distribution for the CompensationLevel column is as follows:\n",
    "\n",
    "**NaN (Missing):** 41,165 entries<br />\n",
    "**Medium Compensation:**  22,846 entries<br />\n",
    "**High Compensation:**  13,066 entries<br />\n",
    "**Low Compensation:**  12,107 entries<br />\n",
    "\n",
    "The NaN values represent missing data in the ConvertedCompYearly column. For the purpose of classification, we will need to handle these missing values, either by imputing them or excluding them from our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d4a878",
   "metadata": {},
   "source": [
    "## Step 3: Feature Selection and Engineering\n",
    "\n",
    "In this step, we'll identify columns that could be relevant predictors for a respondent's compensation level. Features such as years of experience, country of residence, education level, and primary field of study are likely to influence compensation. Additionally, we might need to encode categorical features and normalize numerical ones to make them suitable for machine learning algorithms.\n",
    "\n",
    "**3.1: Select Relevant Features**\n",
    "\n",
    "Let's start by selecting a subset of columns that we believe could be relevant predictors. We'll also inspect these columns for any preliminary cleaning or transformation they might require."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "631e484d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>EdLevel</th>\n",
       "      <th>YearsCode</th>\n",
       "      <th>YearsCodePro</th>\n",
       "      <th>DevType</th>\n",
       "      <th>OrgSize</th>\n",
       "      <th>TechList</th>\n",
       "      <th>CompensationLevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>18-24 years old</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>25-34 years old</td>\n",
       "      <td>Bachelor’s degree (B.A., B.S., B.Eng., etc.)</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>Senior Executive (C-Suite, VP, etc.)</td>\n",
       "      <td>2 to 9 employees</td>\n",
       "      <td>Investigate</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>45-54 years old</td>\n",
       "      <td>Bachelor’s degree (B.A., B.S., B.Eng., etc.)</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>Developer, back-end</td>\n",
       "      <td>5,000 to 9,999 employees</td>\n",
       "      <td>Given a list</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>25-34 years old</td>\n",
       "      <td>Bachelor’s degree (B.A., B.S., B.Eng., etc.)</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>Developer, front-end</td>\n",
       "      <td>100 to 499 employees</td>\n",
       "      <td>Investigate</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Philippines</td>\n",
       "      <td>25-34 years old</td>\n",
       "      <td>Bachelor’s degree (B.A., B.S., B.Eng., etc.)</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>Developer, full-stack</td>\n",
       "      <td>20 to 99 employees</td>\n",
       "      <td>Investigate</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Country              Age  \\\n",
       "0                       NaN  18-24 years old   \n",
       "1  United States of America  25-34 years old   \n",
       "2  United States of America  45-54 years old   \n",
       "3  United States of America  25-34 years old   \n",
       "4               Philippines  25-34 years old   \n",
       "\n",
       "                                        EdLevel YearsCode YearsCodePro  \\\n",
       "0                                           NaN       NaN          NaN   \n",
       "1  Bachelor’s degree (B.A., B.S., B.Eng., etc.)        18            9   \n",
       "2  Bachelor’s degree (B.A., B.S., B.Eng., etc.)        27           23   \n",
       "3  Bachelor’s degree (B.A., B.S., B.Eng., etc.)        12            7   \n",
       "4  Bachelor’s degree (B.A., B.S., B.Eng., etc.)         6            4   \n",
       "\n",
       "                                DevType                   OrgSize  \\\n",
       "0                                   NaN                       NaN   \n",
       "1  Senior Executive (C-Suite, VP, etc.)          2 to 9 employees   \n",
       "2                   Developer, back-end  5,000 to 9,999 employees   \n",
       "3                  Developer, front-end      100 to 499 employees   \n",
       "4                 Developer, full-stack        20 to 99 employees   \n",
       "\n",
       "       TechList CompensationLevel  \n",
       "0           NaN               NaN  \n",
       "1   Investigate              High  \n",
       "2  Given a list              High  \n",
       "3   Investigate              High  \n",
       "4   Investigate               Low  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting a subset of potentially relevant columns\n",
    "selected_features = [\n",
    "    'Country', 'Age', 'EdLevel', 'YearsCode', 'YearsCodePro', 'DevType', 'OrgSize', 'TechList'\n",
    "]\n",
    "\n",
    "# Extracting these columns from the dataset along with the target variable\n",
    "subset_data = data[selected_features + ['CompensationLevel']].copy()\n",
    "\n",
    "# Display the first few rows of the selected subset\n",
    "subset_data_head = subset_data.head()\n",
    "\n",
    "subset_data_head\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903b901a",
   "metadata": {},
   "source": [
    "The table above presents the selected features, including 'Country', 'Age', 'EdLevel', 'YearsCode', 'YearsCodePro', 'DevType', 'OrgSize', and 'TechList'. Additionally, the CompensationLevel column classifies respondents' annual compensation into \"Low\", \"Medium\", or \"High\" categories based on the previously defined percentiles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cdb8b0",
   "metadata": {},
   "source": [
    "## 3.2: Handle Missing Values\n",
    "\n",
    "Missing data can affect the performance of machine learning models. Different strategies can be used to handle missing values, such as imputation (filling in missing values) or removing rows with missing data. The choice of strategy often depends on the nature and amount of the missing data.\n",
    "\n",
    "Let's start by checking for missing values in our selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "849e1ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country               1211\n",
       "Age                      0\n",
       "EdLevel               1211\n",
       "YearsCode             1749\n",
       "YearsCodePro         23048\n",
       "DevType              12312\n",
       "OrgSize              24141\n",
       "TechList             28333\n",
       "CompensationLevel    41165\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values in the subset_data\n",
    "missing_values = subset_data.isnull().sum()\n",
    "\n",
    "missing_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb4b028",
   "metadata": {},
   "source": [
    "Given the significant amount of missing data in certain columns, we need to decide on a strategy for each:\n",
    "\n",
    "1. For columns like Country, EdLevel, and YearsCode with relatively fewer missing entries, we can either impute using a common strategy (like mode) or remove those rows.\n",
    "2. For columns like YearsCodePro, DevType, OrgSize, and TechList with a more substantial amount of missing data, we might consider encoding the missing values as a separate category (e.g., \"Unknown\" or \"Not Provided\").\n",
    "3. For the target column CompensationLevel, since we cannot impute the class labels without introducing bias, we should remove rows with missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1babda6b",
   "metadata": {},
   "source": [
    "### 3.2.1: Impute or Remove Missing Values for Selected Columns\n",
    "\n",
    "For columns with relatively fewer missing entries, we can either fill in the missing values or remove those specific rows. Given the data's nature, we'll use the mode (most frequent value) for categorical columns and median for numerical columns, as these are robust measures that are less influenced by outliers.\n",
    "\n",
    "Let's start by imputing missing values for Country, EdLevel, and YearsCode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cf1da1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country               1211\n",
       "Age                      0\n",
       "EdLevel               1211\n",
       "YearsCode                0\n",
       "YearsCodePro         23048\n",
       "DevType              12312\n",
       "OrgSize              24141\n",
       "TechList             28333\n",
       "CompensationLevel    41165\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert textual representations to numeric values\n",
    "subset_data['YearsCode'].replace({'Less than 1 year': '0', 'More than 50 years': '51'}, inplace=True)\n",
    "\n",
    "# Convert the entire column to numeric datatype\n",
    "subset_data['YearsCode'] = pd.to_numeric(subset_data['YearsCode'], errors='coerce')\n",
    "\n",
    "# Impute missing values with median\n",
    "subset_data['YearsCode'].fillna(subset_data['YearsCode'].median(), inplace=True)\n",
    "\n",
    "# Check remaining missing values again\n",
    "remaining_missing_values = subset_data.isnull().sum()\n",
    "\n",
    "remaining_missing_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c591f376",
   "metadata": {},
   "source": [
    "As seen in the updated missing values summary:\n",
    "\n",
    "YearsCodePro, DevType, OrgSize, and TechList have substantial missing data. As discussed, we can consider encoding these missing values as a separate category, such as \"Not Provided\" or \"Unknown\".\n",
    "We will handle the missing values in the target column CompensationLevel later by excluding those records from our dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553bfb84",
   "metadata": {},
   "source": [
    "### 3.2.2: Encode Missing Values for Columns with Substantial Missing Data\n",
    "\n",
    "For columns with a significant amount of missing data, introducing a new category like \"Not Provided\" or \"Unknown\" can be useful. This allows us to retain the records without introducing potential biases through imputation. The new category effectively becomes an additional feature for the model, capturing the absence of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "adb8c133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country               1211\n",
       "Age                      0\n",
       "EdLevel               1211\n",
       "YearsCode                0\n",
       "YearsCodePro             0\n",
       "DevType                  0\n",
       "OrgSize                  0\n",
       "TechList                 0\n",
       "CompensationLevel    41165\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode missing values as \"Not Provided\"\n",
    "columns_with_high_missing = ['YearsCodePro', 'DevType', 'OrgSize', 'TechList']\n",
    "for col in columns_with_high_missing:\n",
    "    subset_data[col].fillna('Not Provided', inplace=True)\n",
    "\n",
    "# Check for any remaining missing values\n",
    "remaining_missing_values = subset_data.isnull().sum()\n",
    "\n",
    "remaining_missing_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ea8eb2",
   "metadata": {},
   "source": [
    "The missing values for YearsCodePro, DevType, OrgSize, and TechList have been successfully encoded as \"Not Provided\".\n",
    "\n",
    "\n",
    "Considering the nature of the dataset (results from a survey), and the fact that the missing values in 'CompensationLevel' are likely not missing completely at random, we'll use a combination of techniques:\n",
    "\n",
    "1. Impute the 'Country' and 'EdLevel' columns with the mode since they have a relatively smaller number of missing values.\n",
    "2. Retain the rows where 'CompensationLevel' is not missing. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8940f041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country              0\n",
      "Age                  0\n",
      "EdLevel              0\n",
      "YearsCode            0\n",
      "YearsCodePro         0\n",
      "DevType              0\n",
      "OrgSize              0\n",
      "TechList             0\n",
      "CompensationLevel    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Impute 'Country' and 'EdLevel' with mode\n",
    "subset_data['Country'].fillna(subset_data['Country'].mode()[0], inplace=True)\n",
    "subset_data['EdLevel'].fillna(subset_data['EdLevel'].mode()[0], inplace=True)\n",
    "\n",
    "# Retain rows where 'CompensationLevel' is not missing\n",
    "subset_data = subset_data.dropna(subset=['CompensationLevel'])\n",
    "\n",
    "# Check the remaining missing values\n",
    "remaining_missing_values = subset_data.isnull().sum()\n",
    "print(remaining_missing_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468ab052",
   "metadata": {},
   "source": [
    "## 3.3: Encode Categorical Variables with Label Encoding\n",
    "\n",
    "Label encoding involves converting each value in a column to a number. For example, in a column with values \"Low\", \"Medium\", and \"High\", label encoding might represent them as 0, 1, and 2, respectively. This method is quick and straightforward, but it does introduce an ordinal relationship that might not be present in the original data. This is something to be mindful of when using certain algorithms.\n",
    "\n",
    "Let's proceed with label encoding the categorical columns in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b01b7103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>EdLevel</th>\n",
       "      <th>YearsCode</th>\n",
       "      <th>YearsCodePro</th>\n",
       "      <th>DevType</th>\n",
       "      <th>OrgSize</th>\n",
       "      <th>TechList</th>\n",
       "      <th>CompensationLevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>49</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>163</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>47</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>161</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>21.0</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country  Age  EdLevel  YearsCode  YearsCodePro  DevType  OrgSize  TechList  \\\n",
       "1      163    1        1       18.0            49       31        4         1   \n",
       "2      163    3        1       27.0            15       11        6         0   \n",
       "3      163    1        1       12.0            47       14        3         1   \n",
       "4      119    1        1        6.0            33       15        5         1   \n",
       "5      161    2        6       21.0            13       11        3         2   \n",
       "\n",
       "  CompensationLevel  \n",
       "1              High  \n",
       "2              High  \n",
       "3              High  \n",
       "4               Low  \n",
       "5            Medium  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Instantiate the label encoder\n",
    "label_encoders = {}\n",
    "\n",
    "# Encode categorical columns using label encoding\n",
    "for col in subset_data.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    subset_data[col] = le.fit_transform(subset_data[col])\n",
    "    label_encoders[col] = le  # Storing the encoder for potential inverse transformations later\n",
    "\n",
    "# Display the first few rows of the encoded dataset\n",
    "encoded_subset_data_head = subset_data.head()\n",
    "\n",
    "encoded_subset_data_head\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2066ccc",
   "metadata": {},
   "source": [
    "The categorical columns have been successfully label-encoded.\n",
    "\n",
    "\n",
    "The table now presents the selected features with their encoded values. For example, the Country column has been transformed from country names to numerical labels. We've stored each label encoder in the label_encoders dictionary, allowing us to potentially reverse the encoding later if needed.\n",
    "\n",
    "The next steps involve further feature engineering and data transformation to prepare our dataset for machine learning algorithms. This might include:\n",
    "\n",
    "* Parsing the TechList column to create binary columns for each technology (if it has multiple entries separated by semicolons or other delimiters).\n",
    "* Normalizing numerical features to ensure they're on a similar scale.\n",
    "* Splitting the data into training and testing sets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55224d4c",
   "metadata": {},
   "source": [
    "## 3.4: Feature Engineering and Transformation\n",
    "\n",
    "Feature engineering involves creating new features or modifying existing ones to better represent the underlying patterns in the data. This step can significantly improve model performance.\n",
    "\n",
    "For this dataset, the TechList column seems to contain multiple technologies separated by semicolons. We can create binary columns for each technology to better represent this data. Additionally, we'll normalize numerical columns to ensure they're on a similar scale.\n",
    "\n",
    "### 3.4.1: Parse TechList Column\n",
    "Let's start by parsing the TechList column and creating binary columns for each technology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d1a9e01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>EdLevel</th>\n",
       "      <th>YearsCode</th>\n",
       "      <th>YearsCodePro</th>\n",
       "      <th>DevType</th>\n",
       "      <th>OrgSize</th>\n",
       "      <th>CompensationLevel</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>49</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>High</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>163</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>High</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>47</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>High</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>33</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>161</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>21.0</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>Medium</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country  Age  EdLevel  YearsCode  YearsCodePro  DevType  OrgSize  \\\n",
       "1      163    1        1       18.0            49       31        4   \n",
       "2      163    3        1       27.0            15       11        6   \n",
       "3      163    1        1       12.0            47       14        3   \n",
       "4      119    1        1        6.0            33       15        5   \n",
       "5      161    2        6       21.0            13       11        3   \n",
       "\n",
       "  CompensationLevel  0  1  2  3  \n",
       "1              High  0  1  0  0  \n",
       "2              High  1  0  0  0  \n",
       "3              High  0  1  0  0  \n",
       "4               Low  0  1  0  0  \n",
       "5            Medium  0  0  1  0  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the 'TechList' column to string type\n",
    "subset_data['TechList'] = subset_data['TechList'].astype(str)\n",
    "\n",
    "# Parse the 'TechList' column to create binary columns for each technology\n",
    "tech_dummies = subset_data['TechList'].str.get_dummies(sep=';')\n",
    "\n",
    "# Drop the original 'TechList' column and append the new binary columns\n",
    "subset_data = pd.concat([subset_data.drop('TechList', axis=1), tech_dummies], axis=1)\n",
    "\n",
    "# Display the first few rows of the transformed dataset\n",
    "transformed_subset_data_head = subset_data.head()\n",
    "\n",
    "transformed_subset_data_head\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e835d648",
   "metadata": {},
   "source": [
    "The TechList column has been successfully parsed, and binary columns have been created for each technology.\n",
    "\n",
    "\n",
    "The new binary columns represent different technologies that respondents have indicated familiarity with. Each column has a value of 1 if the respondent is familiar with that technology and 0 otherwise.\n",
    "\n",
    "### 3.4.2: Normalize Numerical Features\n",
    "\n",
    "Normalization is the process of scaling numeric features to have a mean of 0 and a standard deviation of 1. This ensures that all numeric features contribute equally to the performance of algorithms, especially those sensitive to feature scales like gradient descent-based methods or distance-based algorithms.\n",
    "\n",
    "We'll use the StandardScaler from scikit-learn to normalize our numeric columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "45ca8d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>EdLevel</th>\n",
       "      <th>YearsCode</th>\n",
       "      <th>YearsCodePro</th>\n",
       "      <th>DevType</th>\n",
       "      <th>OrgSize</th>\n",
       "      <th>CompensationLevel</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.080945</td>\n",
       "      <td>-0.535685</td>\n",
       "      <td>-0.673255</td>\n",
       "      <td>0.236892</td>\n",
       "      <td>1.422867</td>\n",
       "      <td>2.855297</td>\n",
       "      <td>0.164816</td>\n",
       "      <td>High</td>\n",
       "      <td>-0.242838</td>\n",
       "      <td>0.876247</td>\n",
       "      <td>-0.755165</td>\n",
       "      <td>-0.125364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.080945</td>\n",
       "      <td>1.451803</td>\n",
       "      <td>-0.673255</td>\n",
       "      <td>1.148537</td>\n",
       "      <td>-0.449215</td>\n",
       "      <td>-0.590402</td>\n",
       "      <td>1.016917</td>\n",
       "      <td>High</td>\n",
       "      <td>4.117978</td>\n",
       "      <td>-1.141230</td>\n",
       "      <td>-0.755165</td>\n",
       "      <td>-0.125364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.080945</td>\n",
       "      <td>-0.535685</td>\n",
       "      <td>-0.673255</td>\n",
       "      <td>-0.370872</td>\n",
       "      <td>1.312745</td>\n",
       "      <td>-0.073547</td>\n",
       "      <td>-0.261234</td>\n",
       "      <td>High</td>\n",
       "      <td>-0.242838</td>\n",
       "      <td>0.876247</td>\n",
       "      <td>-0.755165</td>\n",
       "      <td>-0.125364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.287853</td>\n",
       "      <td>-0.535685</td>\n",
       "      <td>-0.673255</td>\n",
       "      <td>-0.978635</td>\n",
       "      <td>0.541888</td>\n",
       "      <td>0.098738</td>\n",
       "      <td>0.590867</td>\n",
       "      <td>Low</td>\n",
       "      <td>-0.242838</td>\n",
       "      <td>0.876247</td>\n",
       "      <td>-0.755165</td>\n",
       "      <td>-0.125364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.044895</td>\n",
       "      <td>0.458059</td>\n",
       "      <td>2.080216</td>\n",
       "      <td>0.540774</td>\n",
       "      <td>-0.559337</td>\n",
       "      <td>-0.590402</td>\n",
       "      <td>-0.261234</td>\n",
       "      <td>Medium</td>\n",
       "      <td>-0.242838</td>\n",
       "      <td>-1.141230</td>\n",
       "      <td>1.324213</td>\n",
       "      <td>-0.125364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Country       Age   EdLevel  YearsCode  YearsCodePro   DevType   OrgSize  \\\n",
       "1  1.080945 -0.535685 -0.673255   0.236892      1.422867  2.855297  0.164816   \n",
       "2  1.080945  1.451803 -0.673255   1.148537     -0.449215 -0.590402  1.016917   \n",
       "3  1.080945 -0.535685 -0.673255  -0.370872      1.312745 -0.073547 -0.261234   \n",
       "4  0.287853 -0.535685 -0.673255  -0.978635      0.541888  0.098738  0.590867   \n",
       "5  1.044895  0.458059  2.080216   0.540774     -0.559337 -0.590402 -0.261234   \n",
       "\n",
       "  CompensationLevel         0         1         2         3  \n",
       "1              High -0.242838  0.876247 -0.755165 -0.125364  \n",
       "2              High  4.117978 -1.141230 -0.755165 -0.125364  \n",
       "3              High -0.242838  0.876247 -0.755165 -0.125364  \n",
       "4               Low -0.242838  0.876247 -0.755165 -0.125364  \n",
       "5            Medium -0.242838 -1.141230  1.324213 -0.125364  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Identify numerical columns\n",
    "numerical_columns = subset_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Instantiate the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Normalize the numerical columns\n",
    "subset_data[numerical_columns] = scaler.fit_transform(subset_data[numerical_columns])\n",
    "\n",
    "# Display the first few rows of the normalized dataset\n",
    "normalized_subset_data_head = subset_data.head()\n",
    "\n",
    "normalized_subset_data_head\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2052c865",
   "metadata": {},
   "source": [
    "The table now presents the selected features with their normalized values. For example, the Country column has values around 0, which indicates they've been centered, and the standard deviation for these columns is now 1.\n",
    "\n",
    "With normalization complete, the next step is to split the data into training and testing sets, ensuring we remove any rows with missing target values in CompensationLevel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd063d0c",
   "metadata": {},
   "source": [
    "## 3.5: Splitting the Data into Training and Testing Sets\n",
    "\n",
    "Splitting the dataset into training and testing sets allows us to train our machine learning models on one subset and evaluate their performance on another, unseen subset. This helps ensure that our models generalize well to new data and are not just fitting the training data too closely (overfitting).\n",
    "\n",
    "Let's proceed with this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1196ea81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X_train': (38415, 11),\n",
       " 'X_test': (9604, 11),\n",
       " 'y_train': (38415,),\n",
       " 'y_test': (9604,)}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features and target variable\n",
    "X = subset_data.drop('CompensationLevel', axis=1)\n",
    "y = subset_data['CompensationLevel']\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the training and testing sets\n",
    "train_test_shapes = {\n",
    "    \"X_train\": X_train.shape,\n",
    "    \"X_test\": X_test.shape,\n",
    "    \"y_train\": y_train.shape,\n",
    "    \"y_test\": y_test.shape\n",
    "}\n",
    "\n",
    "train_test_shapes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eba103",
   "metadata": {},
   "source": [
    "This means we'll train our machine learning model on 38,415 samples and then evaluate its performance on 9,604 unseen samples.\n",
    "\n",
    "With the data prepared, we can proceed to model training and evaluation. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e79a8d",
   "metadata": {},
   "source": [
    "## 4.1: Model Training and Evaluation\n",
    "\n",
    "Given that our target variable, CompensationLevel, is a categorical variable with three classes (Low, Medium, High), this is a multiclass classification problem. There are various algorithms suitable for multiclass classification, including:\n",
    "\n",
    "1. Decision Trees\n",
    "2. Random Forests\n",
    "3. Gradient Boosting Machines\n",
    "4. Logistic Regression (with multinomial setting)\n",
    "5. Support Vector Machines (with appropriate kernel and settings)\n",
    "6. Neural Networks\n",
    "\n",
    "After training each model, we'll evaluate their performance on the test set and compare their metrics (like accuracy and F1-score) in a table.\n",
    "\n",
    "By comparing the performance of different models, we can understand which models are best suited for our dataset and problem. This aids in model selection and provides insights into potential areas of improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4141f4be",
   "metadata": {},
   "source": [
    "**1. Decision Trees**\n",
    "\n",
    "Let's begin by training a Decision Tree classifier on our training data and evaluating its performance on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7bc90694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6213036234902124, 0.6213166556483987)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Initialize the Decision Tree classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "dt_predictions = dt_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
    "dt_f1 = f1_score(y_test, dt_predictions, average='weighted')\n",
    "\n",
    "dt_accuracy, dt_f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4aabe2",
   "metadata": {},
   "source": [
    "The accuracy represents the proportion of correctly classified instances out of the total instances. The F1-score is a measure that takes into account both precision (the number of correct positive results divided by the number of all positive results) and recall (the number of correct positive results divided by the number of positive results that should have been returned). The weighted average of the F1-score computes this metric for each label, and the result is then averaged, taking the number of true instances for each label into account.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0c655d",
   "metadata": {},
   "source": [
    "**2. Random Forests**\n",
    "\n",
    "Next, let's train a Random Forest classifier on our training data and evaluate its performance on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a2ada45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6883590170762183, 0.6866199005816039)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "rf_predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "rf_f1 = f1_score(y_test, rf_predictions, average='weighted')\n",
    "\n",
    "rf_accuracy, rf_f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a663ed",
   "metadata": {},
   "source": [
    "The Random Forest classifier, an ensemble method, shows an improvement in performance compared to the single Decision Tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d4431b",
   "metadata": {},
   "source": [
    "**3. Gradient Boosting Machines (GBM)**\n",
    "\n",
    "Next, let's train a Gradient Boosting classifier and evaluate its performance. Gradient Boosting is a powerful ensemble method that builds trees sequentially, where each tree tries to correct the mistakes of the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43fc730e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7098084131611828, 0.7081931800620362)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize the Gradient Boosting classifier\n",
    "gbm_classifier = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "gbm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "gbm_predictions = gbm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "gbm_accuracy = accuracy_score(y_test, gbm_predictions)\n",
    "gbm_f1 = f1_score(y_test, gbm_predictions, average='weighted')\n",
    "\n",
    "gbm_accuracy, gbm_f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86690ced",
   "metadata": {},
   "source": [
    "The GBM classifier, with its sequential tree-building approach, outperformed both the Decision Tree and Random Forest classifiers on this dataset, indicating the benefits of boosting methods in correcting the errors of previous learners."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3609b9",
   "metadata": {},
   "source": [
    "**4. Logistic Regression (with multinomial setting)**\n",
    "\n",
    "Now, let's train a multinomial Logistic Regression model and evaluate its performance on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b895f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5750728862973761, 0.5592726821212124)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the Logistic Regression classifier with multinomial setting\n",
    "lr_classifier = LogisticRegression(multi_class='multinomial', max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "lr_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "lr_predictions = lr_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "lr_f1 = f1_score(y_test, lr_predictions, average='weighted')\n",
    "\n",
    "lr_accuracy, lr_f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2e4dd6",
   "metadata": {},
   "source": [
    "While logistic regression is a powerful method for binary classification, its performance for this multiclass problem lags behind tree-based methods. This could be due to the linear nature of logistic regression or the need for further hyperparameter tuning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cccbd9c",
   "metadata": {},
   "source": [
    "**5. Support Vector Machines (SVM)**\n",
    "\n",
    "Support Vector Machines are versatile algorithms that can be used for both classification and regression. For multiclass classification, we'll use a one-vs-one strategy: for each pair of classes, a binary classifier is learned, and predictions are made using a voting strategy.\n",
    "\n",
    "Let's train an SVM classifier on our training data and evaluate its performance on the testing data. Please note that this step might take some time due to the size of the dataset and the nature of the SVM algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d1ea556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.53, Weighted F1-Score: 0.44\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Initialize the SVM classifier with a linear kernel and one-vs-one strategy\n",
    "svm_classifier = SVC(kernel='linear', decision_function_shape='ovo', random_state=42)\n",
    "\n",
    "# Train the classifier on the entire training data\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "svm_predictions = svm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "svm_f1 = f1_score(y_test, svm_predictions, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {svm_accuracy:.2f}, Weighted F1-Score: {svm_f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe31523",
   "metadata": {},
   "source": [
    "The SVM's performance is not as high as some of the other models. The performance could potentially improve with more data and tuning, but this would also significantly increase the computational requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8818f96",
   "metadata": {},
   "source": [
    "**6. Neural Networks**\n",
    "\n",
    "Next, let's train a simple Neural Network model and evaluate its performance on the testing data. Neural networks are powerful algorithms that can capture intricate patterns in data, but they also require proper architecture design and parameter tuning. We'll start with a basic architecture for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca46e124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6632653061224489, 0.6588881130890476)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Initialize a simple Neural Network with 2 hidden layers of 50 neurons each\n",
    "nn_classifier = MLPClassifier(hidden_layer_sizes=(50, 50), max_iter=500, random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "nn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "nn_predictions = nn_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "nn_accuracy = accuracy_score(y_test, nn_predictions)\n",
    "nn_f1 = f1_score(y_test, nn_predictions, average='weighted')\n",
    "\n",
    "nn_accuracy, nn_f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77e911b",
   "metadata": {},
   "source": [
    "The Neural Network classifier performed reasonably well on the testing data, considering its simple architecture. With more complex architectures and hyperparameter tuning, Neural Networks can often achieve better performance, but this also comes with an increased risk of overfitting if not handled properly.\n",
    "\n",
    "**Performance Comparison**\n",
    "\n",
    "Now that we've trained multiple models, let's compile their performances into a table for easier comparison. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d6c68b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy (%)</th>\n",
       "      <th>Weighted F1-Score (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.621512</td>\n",
       "      <td>0.621535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.686589</td>\n",
       "      <td>0.684782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.709808</td>\n",
       "      <td>0.708193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.575073</td>\n",
       "      <td>0.559273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.526239</td>\n",
       "      <td>0.440921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.663265</td>\n",
       "      <td>0.658888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy (%)  Weighted F1-Score (%)\n",
       "0        Decision Tree      0.621512               0.621535\n",
       "1        Random Forest      0.686589               0.684782\n",
       "2    Gradient Boosting      0.709808               0.708193\n",
       "3  Logistic Regression      0.575073               0.559273\n",
       "4                  SVM      0.526239               0.440921\n",
       "5       Neural Network      0.663265               0.658888"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the performance metrics of all models into a DataFrame for comparison\n",
    "performance_data = {\n",
    "    \"Model\": [\"Decision Tree\", \"Random Forest\", \"Gradient Boosting\", \"Logistic Regression\", \"SVM\", \"Neural Network\"],\n",
    "    \"Accuracy (%)\": [dt_accuracy, rf_accuracy, gbm_accuracy, lr_accuracy, svm_accuracy, nn_accuracy],\n",
    "    \"Weighted F1-Score (%)\": [dt_f1, rf_f1, gbm_f1, lr_f1, svm_f1, nn_f1]\n",
    "}\n",
    "\n",
    "performance_df = pd.DataFrame(performance_data)\n",
    "\n",
    "# Display the performance comparison table\n",
    "performance_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1b454f",
   "metadata": {},
   "source": [
    "This summary provides a comparative view of the performances of the various models. Gradient Boosting Machines (GBM) performed the best, followed closely by the Random Forest classifier.\n",
    "\n",
    "Given the models we've trained, the most promising candidates for hyperparameter tuning are Random Forest and Gradient Boosting Machines (GBM) since they've shown the best performance so far.\n",
    "\n",
    "For hyperparameter tuning, a common approach is to use grid search or random search with cross-validation.\n",
    "\n",
    "Grid Search: This involves exhaustively trying every combination of hyperparameters in a predefined search space.\n",
    "\n",
    "Random Search: This method samples hyperparameters from a distribution over the search space and is more flexible and often more efficient than grid search.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490e242b",
   "metadata": {},
   "source": [
    "### Random Forests\n",
    "\n",
    "1. Hyperparameters to Consider:\n",
    "\n",
    "- n_estimators: Number of trees in the forest.<br />\n",
    "- max_features: Number of features to consider when looking for the best split.<br />\n",
    "Parameters from Decision Trees (max_depth, min_samples_split, etc.)\n",
    "\n",
    "2. Tuning Strategy:\n",
    "RandomizedSearchCV is a good choice given the larger number of combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "103a9d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'n_estimators': 80,\n",
       "  'min_samples_split': 16,\n",
       "  'min_samples_leaf': 1,\n",
       "  'max_features': 'sqrt',\n",
       "  'max_depth': None,\n",
       "  'criterion': 'gini',\n",
       "  'bootstrap': False},\n",
       " 0.6928022907718339)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Hyperparameter grid for Random Forests\n",
    "rf_param_dist = {\n",
    "    'n_estimators': np.arange(10, 200, 10),\n",
    "    'max_features': ['sqrt', 'log2'],  # Removed 'auto'\n",
    "    'max_depth': [None] + list(np.arange(3, 20)),\n",
    "    'min_samples_split': np.arange(2, 50),\n",
    "    'min_samples_leaf': np.arange(1, 50),\n",
    "    'bootstrap': [True, False],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Random Search for Random Forests\n",
    "rf_search = RandomizedSearchCV(RandomForestClassifier(), rf_param_dist, n_iter=100, cv=5, verbose=1, n_jobs=-1)\n",
    "rf_search.fit(X_train, y_train)\n",
    "\n",
    "# Extract best hyperparameters and best score\n",
    "best_hyperparameters = rf_search.best_params_\n",
    "best_score = rf_search.best_score_\n",
    "\n",
    "best_hyperparameters, best_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4934ff52",
   "metadata": {},
   "source": [
    "From this, it seems that the random search found a combination of hyperparameters that results in about 69.28% cross-validated accuracy. The fine-tuned model shows a slight improvement in accuracy. This indicates that hyperparameter tuning did provide some benefits, even if they are modest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb5b484",
   "metadata": {},
   "source": [
    "### Gradient Boosting Machines\n",
    "\n",
    "1. Hyperparameters to Consider:\n",
    "\n",
    "- n_estimators: Number of boosting stages to run.\n",
    "learning_rate: Shrinks the contribution of each tree.\n",
    "- Parameters from Decision Trees.\n",
    "\n",
    "2. Tuning Strategy:\n",
    "RandomizedSearchCV for initial exploration, followed by GridSearchCV around the best parameters found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e69d259f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [0.01, 0.05, 0.1, 0.5,\n",
       "                                                          1],\n",
       "                                        &#x27;max_depth&#x27;: [None, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32,...\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]),\n",
       "                                        &#x27;min_samples_split&#x27;: array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]),\n",
       "                                        &#x27;n_estimators&#x27;: array([ 10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110, 120, 130,\n",
       "       140, 150, 160, 170, 180, 190]),\n",
       "                                        &#x27;subsample&#x27;: [0.5, 0.6, 0.7, 0.8, 0.9,\n",
       "                                                      1.0]},\n",
       "                   verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [0.01, 0.05, 0.1, 0.5,\n",
       "                                                          1],\n",
       "                                        &#x27;max_depth&#x27;: [None, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32,...\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]),\n",
       "                                        &#x27;min_samples_split&#x27;: array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]),\n",
       "                                        &#x27;n_estimators&#x27;: array([ 10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110, 120, 130,\n",
       "       140, 150, 160, 170, 180, 190]),\n",
       "                                        &#x27;subsample&#x27;: [0.5, 0.6, 0.7, 0.8, 0.9,\n",
       "                                                      1.0]},\n",
       "                   verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': [0.01, 0.05, 0.1, 0.5,\n",
       "                                                          1],\n",
       "                                        'max_depth': [None, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19],\n",
       "                                        'max_features': ['sqrt', 'log2'],\n",
       "                                        'min_samples_leaf': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32,...\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]),\n",
       "                                        'min_samples_split': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]),\n",
       "                                        'n_estimators': array([ 10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110, 120, 130,\n",
       "       140, 150, 160, 170, 180, 190]),\n",
       "                                        'subsample': [0.5, 0.6, 0.7, 0.8, 0.9,\n",
       "                                                      1.0]},\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Hyperparameter grid for GBM\n",
    "gbm_param_dist = {\n",
    "    'n_estimators': np.arange(10, 200, 10),\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.5, 1],\n",
    "    'max_depth': [None] + list(np.arange(3, 20)),\n",
    "    'min_samples_split': np.arange(2, 50),\n",
    "    'min_samples_leaf': np.arange(1, 50),\n",
    "    'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'max_features': [ 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Random Search for GBM\n",
    "gbm_search = RandomizedSearchCV(GradientBoostingClassifier(), gbm_param_dist, n_iter=100, cv=5, verbose=1, n_jobs=-1)\n",
    "gbm_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa90f6e1",
   "metadata": {},
   "source": [
    "We are interested in seeing the performance of all the hyperparameter combinations that were tried, we can use the cv_results_ attribute. This will give us a dictionary with a lot of information, but here's how we can extract some key pieces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bacc48a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               params  mean_test_score  \\\n",
      "20  {'subsample': 1.0, 'n_estimators': 130, 'min_s...         0.724899   \n",
      "0   {'subsample': 1.0, 'n_estimators': 120, 'min_s...         0.722973   \n",
      "35  {'subsample': 0.8, 'n_estimators': 130, 'min_s...         0.721749   \n",
      "1   {'subsample': 1.0, 'n_estimators': 170, 'min_s...         0.721255   \n",
      "49  {'subsample': 0.8, 'n_estimators': 160, 'min_s...         0.720838   \n",
      "\n",
      "    rank_test_score  \n",
      "20                1  \n",
      "0                 2  \n",
      "35                3  \n",
      "1                 4  \n",
      "49                5  \n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(gbm_search.cv_results_)\n",
    "# Display the top 5 hyperparameter combinations by mean test score\n",
    "print(results[['params', 'mean_test_score', 'rank_test_score']].sort_values(by='rank_test_score').head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6deb68",
   "metadata": {},
   "source": [
    "- The best hyperparameters outperformed the rest, but the difference in performance between the top combinations is relatively small. This suggests that GBM is somewhat robust to hyperparameter variations in this range.\n",
    "- A subsample of 1.0, which means that the whole dataset is used for training (no subsampling), appears to be a good choice based on the top two results.\n",
    "- n_estimators around 130 seems to be a favorable choice, as observed from the top results. This means that approximately 130 boosting stages give a good trade-off between performance and potential overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d5fc38",
   "metadata": {},
   "source": [
    "Finally, we will evaluate the performance of the best model on our test data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "07479e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy with Best Model: 0.7291753436068305\n"
     ]
    }
   ],
   "source": [
    "best_gbm = gbm_search.best_estimator_\n",
    "test_predictions = best_gbm.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(f\"Test Accuracy with Best Model: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26847293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       0.77      0.69      0.73      2688\n",
      "         Low       0.76      0.69      0.72      2437\n",
      "      Medium       0.70      0.78      0.74      4479\n",
      "\n",
      "    accuracy                           0.73      9604\n",
      "   macro avg       0.74      0.72      0.73      9604\n",
      "weighted avg       0.73      0.73      0.73      9604\n",
      "\n",
      "[[1845   48  795]\n",
      " [  45 1678  714]\n",
      " [ 509  490 3480]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Predictions using the best GBM model\n",
    "y_pred = gbm_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d17f0a",
   "metadata": {},
   "source": [
    "Let's break down the results:\n",
    "\n",
    "## Classification Report:\n",
    "\n",
    "1. High Compensation:\n",
    "\n",
    "- Precision: 77% of the instances predicted as \"High\" were actually \"High\".\n",
    "- Recall: Out of all the actual \"High\" compensation instances, 69% were correctly predicted by the model.\n",
    "- F1-score: Harmonic mean of precision and recall for this class is 73%.\n",
    "- Support: There were 2,688 actual instances of this class in the test set.\n",
    "\n",
    "2. Low Compensation:\n",
    "\n",
    "- Precision: 76% of the instances predicted as \"Low\" were actually \"Low\".\n",
    "- Recall: 69% of the actual \"Low\" compensation instances were correctly predicted.\n",
    "- F1-score: 72%.\n",
    "- Support: 2,437 actual instances.\n",
    "\n",
    "3. Medium Compensation:\n",
    "\n",
    "- Precision: 70% of the instances predicted as \"Medium\" were indeed \"Medium\".\n",
    "- Recall: 78% of the actual \"Medium\" compensation instances were correctly predicted, which is the highest recall among the three classes.\n",
    "- F1-score: 74%.\n",
    "- Support: 4,479 actual instances.\n",
    "\n",
    "### Overall:\n",
    "\n",
    "The model's accuracy on the test set is 73%, which aligns with the previously calculated accuracy.\n",
    "The weighted average F1-score is also 73%, indicating a balanced performance across the different compensation levels, considering the number of instances of each class.\n",
    "\n",
    "### Confusion Matrix:\n",
    "\n",
    "The rows represent the actual classes, and the columns represent the predicted classes.\n",
    "\n",
    "- High Compensation: 1,845 were correctly classified (True Positive for \"High\"), 48 were misclassified as \"Low\", and 795 were misclassified as \"Medium\".\n",
    "- Low Compensation: 1,678 were correctly classified, 45 were misclassified as \"High\", and 714 were misclassified as \"Medium\".\n",
    "- Medium Compensation: 3,480 were correctly classified, 509 were misclassified as \"High\", and 490 were misclassified as \"Low\".\n",
    "\n",
    "The model seems to have the highest difficulty in distinguishing between \"High\" and \"Medium\" compensations, as indicated by the higher off-diagonal values in the confusion matrix.\n",
    "The recall for \"Medium\" is the highest among the classes, meaning the model does a better job capturing the \"Medium\" compensation instances compared to the other two classes.\n",
    "The precision for \"Medium\" is slightly lower than the other classes, indicating some over-prediction for this class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbea3ee",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "Throughout the process of analyzing the developer survey data, we aimed to categorize developers into different compensation levels based on various attributes such as skills, experience, country, and more. Our journey was a clear reminder that data science projects often encompass a wide spectrum of challenges that go beyond just algorithm selection or model training.\n",
    "\n",
    "1. Understanding the Data: Our dataset was vast, with over 89,000 entries spanning 84 columns. The preliminary step involved understanding the nature of the data, visualizing distributions, and determining our target variable: the 'CompensationLevel'.\n",
    "\n",
    "2. Data Cleaning & Transformation: We observed a wide range in the annual compensation, suggesting outliers or erroneous entries. Deciding on compensation brackets required using quantiles to create a balanced classification. Moreover, the data contained a significant number of missing values. Handling these appropriately – whether by imputation, encoding, or removal – was pivotal to ensure the quality of the dataset feeding into our models.\n",
    "\n",
    "3. Feature Selection & Engineering: We identified relevant predictors and recognized the importance of features like 'Country', which could significantly influence compensation levels due to economic disparities and cost-of-living variations. Other attributes such as years of experience, education level, and developer type also played crucial roles.\n",
    "\n",
    "4. Challenges: One of the main challenges was the significant amount of missing data in our target variable, 'CompensationLevel'. Considering the 10% rule, where if more than 10% of the data for a given feature is missing, it might be considered for removal, we debated various strategies, including interpolation, imputation, and oversampling. However, since this was the variable we aimed to predict, many traditional imputation methods might not have been suitable. Furthermore, the data's nature, being from a survey, added another layer of complexity. Survey data can be inherently biased and might not always capture the full spectrum of the population.\n",
    "\n",
    "5. Limitations & External Factors: The 'Country' feature stood out as a potential influencing factor, given the wide disparities in developer compensations worldwide. Economic conditions, industry demand, and living costs can vary dramatically between countries, potentially skewing results. Additionally, external factors, such as currency fluctuations or political events, can also impact compensation, which might not be captured in the survey.\n",
    "\n",
    "6. Looking Ahead: While we eventually decided on dropping rows with missing target values, future endeavors might involve more advanced techniques, perhaps leveraging external datasets or domain knowledge. Another avenue could be to focus on region-specific models, considering the influence of the 'Country' feature.\n",
    "\n",
    "In conclusion, this project was a testament to the iterative nature of data science. From data cleaning to model evaluation, every step required critical thinking, backed by domain knowledge and data-driven insights. The challenges faced underscore the importance of a robust preprocessing phase and the need to always be cognizant of the underlying biases and limitations inherent in every dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5caa7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
